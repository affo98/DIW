{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ah140\\OneDrive\\itu\\1_semester\\data_in_the_wild\\project\\DIW\\folketinget\\annotation.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ah140/OneDrive/itu/1_semester/data_in_the_wild/project/DIW/folketinget/annotation.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_tok \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_parquet(\u001b[39m'\u001b[39m\u001b[39m./data/df_tokenized.parquet\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_tok = pd.read_parquet('./data/df_tokenized.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotation_data = pd.read_csv('dataraw_annotation/annotation_data.csv')\n",
    "\n",
    "\n",
    "\n",
    "dmeeting = pd.read_parquet('./data/data_meeting.parquet')\n",
    "data_agenda1 = pd.read_parquet('./data/data_agenda1.parquet')\n",
    "data_agenda2 = pd.read_parquet('./data/data_agenda2.parquet')\n",
    "data_agenda3 = pd.read_parquet('./data/data_agenda3.parquet')\n",
    "data_speech1 = pd.read_parquet('./data/data_speech1.parquet')\n",
    "data_speech2 = pd.read_parquet('./data/data_speech2.parquet')\n",
    "data_speech3 = pd.read_parquet('./data/data_speech3.parquet')\n",
    "parMem = pd.read_parquet('./data/parliament_members.parquet')\n",
    "\n",
    "dagenda = pd.concat([data_agenda1, data_agenda2, data_agenda3], axis=0)\n",
    "dspeech = pd.concat([data_speech1, data_speech2, data_speech3], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Agenda items to annotate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(text):\n",
    "  return text.year\n",
    "\n",
    "dagenda[\"year\"] = dagenda[\"date\"].apply(extract_year)\n",
    "dagenda[\"group\"] = dagenda[\"year\"].astype(str) + \"_\" + dagenda[\"type\"].astype(str)\n",
    "dagenda[\"unique_id\"] = dagenda[\"meeting_id\"].astype(str) + \"_\" + dagenda[\"agenda_item_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [0] * len(dagenda)\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "for i, (train_idx, val_idx) in enumerate(stratified_kfold.split(X, dagenda.group.to_list())):\n",
    "  val_index = list(val_idx)\n",
    "  temp_df = dagenda.loc[val_index]\n",
    "\n",
    "  duplicates = pd.merge(temp_df, dagenda, on='unique_id', how='inner')\n",
    "  dup_rate = len(duplicates) / len(temp_df) * 100\n",
    "  print(f\"Duplicate Rate for Fold{i}: {dup_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotating '?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We manually annotate these all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotation_together = pd.read_csv('dataraw_annotation/annotation_together.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_q = annotation_data[\n",
    "    (annotation_data['Eisuke_label'] == '?') |\n",
    "    (annotation_data['Andreas_label'] == '?') |\n",
    "    (annotation_data['Anders_label'] == '?')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_q_old = pd.read_csv('dataraw_annotation/annotation_together.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_q = pd.merge(annotation_q, annotation_q_old[['title', 'group', 'label']], on=['title', 'group'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_q.to_csv('dataraw_annotation/annotation_together.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_data = annotation_data[\n",
    "    (annotation_data['Eisuke_label'] != '?') &\n",
    "    (annotation_data['Andreas_label'] != '?') &\n",
    "    (annotation_data['Anders_label'] != '?')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combined_label(row):\n",
    "    count_C = 0\n",
    "    if row['Eisuke_label'] == 'C':\n",
    "        count_C += 1\n",
    "    if row['Andreas_label'] == 'C':\n",
    "        count_C += 1\n",
    "    if row['Anders_label'] == 'C':\n",
    "        count_C += 1\n",
    "    if count_C >= 2:\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'NC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_data['label'] = annotation_data.apply(lambda row: generate_combined_label(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_data = pd.concat([annotation_data, annotation_q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotation_data.to_csv('data/annotation_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
