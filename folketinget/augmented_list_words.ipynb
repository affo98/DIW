{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from gensim.models import KeyedVectors\n",
    "from adjustText import adjust_text\n",
    "import multiprocessing as mp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE = '~/Desktop/dsl_skipgram_2020_m5_f500_epoch2_w5.model.w2v.bin'\n",
    "word_vec_model = KeyedVectors.load_word2vec_format(MODEL_FILE, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helper_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_data = pd.read_parquet(data_path + 'annotation_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tok1 = pd.read_parquet('./data/data_speech1_tok.parquet')\n",
    "df_tok2 = pd.read_parquet('./data/data_speech2_tok.parquet')\n",
    "df = pd.concat([df_tok1, df_tok2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = df[~df[[\"meeting_id\", \"agenda_item_id\"]].apply(tuple, axis=1).isin(annotation_data[[\"meeting_id\",\"agenda_item_id\"]].apply(tuple,axis=1))]\n",
    "res_df.rename(columns={'tokenized_speech':'speech_item_tokenized'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load OG wordlists from annotated data\n",
    "word_list_C = pd.read_parquet('./data/word_lists/word_list_C.parquet')\n",
    "word_list_NC = pd.read_parquet('./data/word_lists/word_list_NC.parquet')\n",
    "word_list_generic = pd.read_csv('./data/word_lists/word_list_generic.txt')\n",
    "\n",
    "word_C_set = set(word_list_C['word'])\n",
    "word_NC_set = set(word_list_NC['word'])\n",
    "word_G_set = set(word_list_generic['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Redo features based on rest of the data\n",
    "res_df = add_features(res_df, word_C_set,word_NC_set,word_G_set,word_vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meeting_id</th>\n",
       "      <th>agenda_item_id</th>\n",
       "      <th>speech_item_id</th>\n",
       "      <th>speech_item_tokenized</th>\n",
       "      <th>C_counts</th>\n",
       "      <th>NC_counts</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>C_percent</th>\n",
       "      <th>NC_percent</th>\n",
       "      <th>average_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[tak, transportminister, optaget, fik, sikkerh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.06342921, 0.0032608698, -0.008996325, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[jamen, godt, spørgsmål, fyn, taler, penge, br...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.06441099, 0.03687072, 0.066466875, -0.1690...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[glad, høre, transportminister, mente, rent, f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.029356077, -0.0070911446, 0.040378388, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>[jamen, spørgeren, siger, klart, forhandlinger...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.04290364, -0.008122435, -0.007846235, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>[rent, spark, sparker, åben, dør, siger, tak, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.034080017, 0.051288128, 0.16791177, 0.0030...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meeting_id  agenda_item_id  speech_item_id  \\\n",
       "0           1               1               1   \n",
       "1           1               1               3   \n",
       "2           1               1               5   \n",
       "3           1               1               7   \n",
       "4           1               1               9   \n",
       "\n",
       "                               speech_item_tokenized  C_counts  NC_counts  \\\n",
       "0  [tak, transportminister, optaget, fik, sikkerh...         0          0   \n",
       "1  [jamen, godt, spørgsmål, fyn, taler, penge, br...         0          0   \n",
       "2  [glad, høre, transportminister, mente, rent, f...         0          0   \n",
       "3  [jamen, spørgeren, siger, klart, forhandlinger...         0          0   \n",
       "4  [rent, spark, sparker, åben, dør, siger, tak, ...         0          0   \n",
       "\n",
       "   num_tokens  C_percent  NC_percent  \\\n",
       "0          30        0.0         0.0   \n",
       "1          24        0.0         0.0   \n",
       "2          51        0.0         0.0   \n",
       "3          11        0.0         0.0   \n",
       "4           6        0.0         0.0   \n",
       "\n",
       "                                         average_vec  \n",
       "0  [-0.06342921, 0.0032608698, -0.008996325, -0.1...  \n",
       "1  [-0.06441099, 0.03687072, 0.066466875, -0.1690...  \n",
       "2  [-0.029356077, -0.0070911446, 0.040378388, -0....  \n",
       "3  [-0.04290364, -0.008122435, -0.007846235, -0.1...  \n",
       "4  [-0.034080017, 0.051288128, 0.16791177, 0.0030...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_potential = res_df[(res_df.C_counts>res_df.NC_counts)]\n",
    "NC_potential = res_df[(res_df.NC_counts>res_df.C_counts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words_C_list = [word for tokens in C_potential.speech_item_tokenized for word in tokens]\n",
    "unique_words_NC_list = [word for tokens in NC_potential.speech_item_tokenized for word in tokens]\n",
    "\n",
    "unique_words_C_dict = Counter(unique_words_C_list)\n",
    "unique_words_NC_dict = Counter(unique_words_NC_list)\n",
    "\n",
    "unique_words_C_df = pd.DataFrame.from_dict(unique_words_C_dict, orient='index', columns=['word_count_C']).reset_index().rename(columns={'index': 'word'})\n",
    "unique_words_NC_df = pd.DataFrame.from_dict(unique_words_NC_dict, orient='index', columns=['word_count_NC']).reset_index().rename(columns={'index': 'word'})\n",
    "\n",
    "unique_words = pd.merge(unique_words_C_df, unique_words_NC_df, on='word', how='outer')\n",
    "unique_words[['word_count_C', 'word_count_NC']] = unique_words[['word_count_C', 'word_count_NC']].fillna(0)\n",
    "unique_words['frequency_C'] = unique_words['word_count_C'] / sum(unique_words_C_df['word_count_C'])\n",
    "unique_words['frequency_NC'] = unique_words['word_count_NC'] / sum(unique_words_NC_df['word_count_NC'])\n",
    "freq_1_NC = 1/ sum(unique_words_NC_df['word_count_NC'])\n",
    "freq_1_C = 1/ sum(unique_words_C_df['word_count_C'])\n",
    "\n",
    "unique_words[\"odds_C\"] = unique_words.apply(lambda row: calculate_odds(row['frequency_C'], row['frequency_NC'], 'C', freq_1_NC), axis=1)\n",
    "unique_words[\"odds_NC\"] = unique_words.apply(lambda row: calculate_odds(row['frequency_NC'], row['frequency_C'], 'NC', freq_1_C), axis=1)\n",
    "\n",
    "unique_words['rank_odds_C'] = unique_words['odds_C'].rank(ascending=False)\n",
    "unique_words['rank_odds_NC'] = unique_words['odds_NC'].rank(ascending=False)\n",
    "\n",
    "unique_words_above_1_C = unique_words[(unique_words['odds_C'] > 1) & (unique_words['frequency_C'] > 0.0001)]\n",
    "                          \n",
    "unique_words_above_1_C['rank'] = unique_words_above_1_C['odds_C'].rank(method='first')\n",
    "unique_words_above_1_C['odds_C_percentile'] = unique_words_above_1_C['rank'].apply(lambda x: map_rank_to_bin(unique_words_above_1_C, x))\n",
    "\n",
    "unique_words_above_1_NC = unique_words[(unique_words['odds_NC'] > 1) & (unique_words['frequency_NC'] > 0.0001)]\n",
    "unique_words_above_1_NC['rank'] = unique_words_above_1_NC['odds_NC'].rank(method='first')\n",
    "unique_words_above_1_NC['odds_NC_percentile'] = unique_words_above_1_NC['rank'].apply(lambda x: map_rank_to_bin(unique_words_above_1_NC, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_percentiles = pd.DataFrame(columns=['percentile', 'perplexity', 'prop_c_not_in_group_c', 'prop_nc_not_in_group_nc', 'cosine_similarities_C', 'cosine_similarities_NC'])\n",
    "\n",
    "# generate different dataframes with different odds\n",
    "\n",
    "for percentile in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]:\n",
    "    data = choose_odds_percentiles(percentile,unique_words_above_1_C,unique_words_above_1_NC,word_vec_model)\n",
    "    \n",
    "    data = k_means(data, 2, perplex=20)\n",
    "    k_means_group_c = data[data['label']=='C']['k_means_group_tsne'].value_counts().idxmax()\n",
    "    data['k_means_group_tsne'] = np.where(data['k_means_group_tsne'] == k_means_group_c, 'C', 'NC')\n",
    "    prop_c_not_in_group_c = len(data[(data['label']=='C') & (data['k_means_group_tsne'] == 'NC')]) / len(data[data['label']=='C'])\n",
    "    prop_nc_not_in_group_nc = len(data[(data['label']=='NC') & (data['k_means_group_tsne'] == 'C')]) / len(data[data['label']=='NC'])\n",
    "\n",
    "    cosine_similarities_C = cosine_similarities(data, 'C', word_vec_model)\n",
    "    cosine_similarities_NC = cosine_similarities(data, 'NC', word_vec_model)\n",
    "\n",
    "    data_df = pd.DataFrame({\n",
    "        'percentile': [percentile],\n",
    "        'perplexity': [20],\n",
    "        'prop_c_not_in_group_c': [prop_c_not_in_group_c],\n",
    "        'prop_nc_not_in_group_nc': [prop_nc_not_in_group_nc],\n",
    "        'cosine_similarities_C': [cosine_similarities_C],\n",
    "        'cosine_similarities_NC': [cosine_similarities_NC]\n",
    "    })\n",
    "\n",
    "    df_percentiles = pd.concat([df_percentiles, data_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_percentiles['percentile'], df_percentiles['cosine_similarities_C'], marker='o', label='C', color = 'blue')\n",
    "plt.plot(df_percentiles['percentile'], df_percentiles['cosine_similarities_NC'], marker='o', label='NC', color='red')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Odds percentile')\n",
    "plt.ylabel('Cosine Similarity')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_k_means_C(df):\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    df = df[df['label']=='C']\n",
    "    df['label_numeric'] = pd.Categorical(df['classification']).codes\n",
    "    colors = ['b', 'c', 'y', 'm']\n",
    "    scatter_TP = plt.scatter(x=df[df['classification']=='TP']['embedded_data1'], y=df[df['classification']=='TP']['embedded_data2'], marker='o', color=colors[0], s = 4)\n",
    "    scatter_FN = plt.scatter(x=df[df['classification']=='FN']['embedded_data1'], y=df[df['classification']=='FN']['embedded_data2'], marker='x', color=colors[3], s = 4)\n",
    "    \n",
    "    texts = [plt.text(row['embedded_data1'], row['embedded_data2'], row['word'], fontsize=6, ha='right') for i, row in df.iterrows()]\n",
    "\n",
    "    adjust_text(texts, arrowprops=dict(arrowstyle='-', color='black'), force_text=0.5, force_points=0.5)\n",
    "    \n",
    "    plt.legend((scatter_TP, scatter_FN),\n",
    "           ('True positive', 'False negative'),\n",
    "           loc='upper right',\n",
    "           fontsize=12)\n",
    "    \n",
    "    plt.savefig('plotC.svg', format='svg')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_85 = pd.concat([choose_odds_percentiles(18,unique_words_above_1_C,unique_words_above_1_NC,word_vec_model),\n",
    "                           choose_odds_percentiles(19,unique_words_above_1_C,unique_words_above_1_NC,word_vec_model), \n",
    "                           choose_odds_percentiles(20,unique_words_above_1_C,unique_words_above_1_NC,word_vec_model)])\n",
    "percentile_85 = k_means(percentile_85, 2, perplex=20)\n",
    "k_means_group_c = percentile_85[percentile_85['label']=='C']['k_means_group_tsne'].value_counts().idxmax()\n",
    "percentile_85['k_means_group_tsne'] = np.where(percentile_85['k_means_group_tsne'] == k_means_group_c, 'C', 'NC')\n",
    "\n",
    "percentile_85['classification'] = np.where(\n",
    "    (percentile_85['label'] == 'C') & (percentile_85['k_means_group_tsne'] == 'C'), 'TP',\n",
    "    np.where((percentile_85['label'] == 'NC') & (percentile_85['k_means_group_tsne'] == 'NC'), 'TN',\n",
    "             np.where((percentile_85['label'] == 'C') & (percentile_85['k_means_group_tsne'] == 'NC'), 'FN', 'FP')))\n",
    "\n",
    "# plot_k_means_C(percentile_85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually check wordlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generic wordlists\n",
    "\n",
    "#use 95 percentiles to find shared common words\n",
    "data_C = unique_words.loc[unique_words[\"word_count_C\"] > 0, 'frequency_C']\n",
    "percentile_99_C = np.percentile(data_C, 99)\n",
    "\n",
    "data_NC = unique_words.loc[unique_words[\"word_count_NC\"] > 0, 'frequency_NC']\n",
    "percentile_99_NC = np.percentile(data_NC, 99)\n",
    "\n",
    "generic_words_list = unique_words[(unique_words.frequency_C>percentile_99_C)&(unique_words.frequency_NC>percentile_99_NC)& \n",
    "                                  (unique_words.odds_C > 0.9) & (unique_words.odds_C < 1.1) &\n",
    "                                  (unique_words.odds_NC > 0.9) & (unique_words.odds_NC < 1.1)].word.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open('C_TP_augment.txt', 'w',  encoding='utf-8') as file:\n",
    "#     for item in percentile_85[(percentile_85['classification']=='TP')& (~(percentile_85['word'].isin(word_list_C['word'])))]['word'].tolist():\n",
    "#         file.write(str(item) + '\\n')\n",
    "            \n",
    "# with open('C_FN_augment.txt', 'w', encoding='utf-8') as file:\n",
    "#     for item in percentile_85[(percentile_85['classification']=='FN')& (~(percentile_85['word'].isin(word_list_C['word'])))]['word'].tolist():\n",
    "#         file.write(str(item) + '\\n')\n",
    "\n",
    "# with open('NC_augment.txt', 'w', encoding='utf-8') as file:\n",
    "#     for item in percentile_85[(percentile_85['label']=='NC')& (~(percentile_85['word'].isin(word_list_C['word'])))]['word'].tolist():\n",
    "#         file.write(str(item) + '\\n')      \n",
    "\n",
    "# with open('./data/word_lists/word_list_generic_augmented_99.txt', 'w', encoding='utf-8') as file:\n",
    "#     for item in generic_words_list:\n",
    "#         file.write(str(item) + '\\n')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list_C_augmented = pd.read_csv('C.txt', index_col = None)\n",
    "word_list_C_augmented = pd.merge(word_list_C_augmented, percentile_85[['word', 'odds_C']], on = 'word', how = 'left')\n",
    "# word_list_C_augmented.to_parquet('./data/word_lists/word_list_C_augmented.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_list_NC_augmented = pd.read_csv('NC_augment.txt', index_col = None)\n",
    "word_list_NC_augmented = pd.merge(word_list_NC_augmented, percentile_85[['word', 'odds_NC']], on = 'word', how = 'left')\n",
    "# word_list_NC_augmented.to_parquet('./data/word_lists/word_list_NC_augmented.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
