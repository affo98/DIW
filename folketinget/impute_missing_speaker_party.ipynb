{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_speech1 = pd.read_parquet('./data/data_speech1.parquet')\n",
    "data_speech2 = pd.read_parquet('./data/data_speech2.parquet')\n",
    "data_speech3 = pd.read_parquet('./data/data_speech3.parquet')\n",
    "dspeech = pd.concat([data_speech1, data_speech2, data_speech3], axis=0)\n",
    "dmeeting = pd.read_parquet('./data/data_meeting.parquet')\n",
    "parMem = pd.read_parquet('./data/parliament_members.parquet')\n",
    "dspeech = pd.merge(dspeech, dmeeting[['meeting_id', 'date']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dataset with speakers that had missing party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_party = dspeech[dspeech['speaker_party'].isnull()] \n",
    "missing_party = pd.merge(missing_party, dmeeting[['meeting_id', 'date']])\n",
    "missing_party = missing_party[['speaker_name', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>speaker_party</th>\n",
       "      <th>period_start</th>\n",
       "      <th>period_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thomas Adelskov</td>\n",
       "      <td>Socialdemokratiet</td>\n",
       "      <td>2005-02-08</td>\n",
       "      <td>2007-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simon Emil Ammitzbøll</td>\n",
       "      <td>Det Radikale Venstre</td>\n",
       "      <td>2005-02-08</td>\n",
       "      <td>2007-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hans Andersen</td>\n",
       "      <td>Venstre</td>\n",
       "      <td>2005-02-08</td>\n",
       "      <td>2007-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jytte Andersen</td>\n",
       "      <td>Socialdemokratiet</td>\n",
       "      <td>2005-02-08</td>\n",
       "      <td>2007-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kim Andersen</td>\n",
       "      <td>Venstre</td>\n",
       "      <td>2005-02-08</td>\n",
       "      <td>2007-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>Theresa Scavenius</td>\n",
       "      <td>Alternativet</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>2023-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>Anna Falkenberg</td>\n",
       "      <td>Sambandsflokkurin</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>2023-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>Sjúrður Skaale</td>\n",
       "      <td>Javnaðarflokkurin</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>2023-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>Aaja Chemnitz Driefer</td>\n",
       "      <td>Inuit Ataqatigiit</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>2023-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>Aki-Matilda Høegh-Dam</td>\n",
       "      <td>Siumut</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>2023-09-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1074 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               speaker_name         speaker_party period_start  period_end\n",
       "0           Thomas Adelskov     Socialdemokratiet   2005-02-08  2007-11-13\n",
       "1     Simon Emil Ammitzbøll  Det Radikale Venstre   2005-02-08  2007-11-13\n",
       "2             Hans Andersen               Venstre   2005-02-08  2007-11-13\n",
       "3            Jytte Andersen     Socialdemokratiet   2005-02-08  2007-11-13\n",
       "4              Kim Andersen               Venstre   2005-02-08  2007-11-13\n",
       "...                     ...                   ...          ...         ...\n",
       "1069      Theresa Scavenius          Alternativet   2022-11-01  2023-09-07\n",
       "1070        Anna Falkenberg     Sambandsflokkurin   2022-11-01  2023-09-07\n",
       "1071         Sjúrður Skaale     Javnaðarflokkurin   2022-11-01  2023-09-07\n",
       "1072  Aaja Chemnitz Driefer     Inuit Ataqatigiit   2022-11-01  2023-09-07\n",
       "1073  Aki-Matilda Høegh-Dam                Siumut   2022-11-01  2023-09-07\n",
       "\n",
       "[1074 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parMem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add speakers that were not in parliament members dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some speakers with missing party were not in the parliament members dataset.\n",
    "We find these and scrape them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charlotte Sahl-Madsen\n",
      "First day 2010-02-25 00:00:00\n",
      "Last day 2011-05-26 00:00:00\n",
      "\n",
      "\n",
      "Joy Mogensen\n",
      "First day 2020-01-15 00:00:00\n",
      "Last day 2021-05-26 00:00:00\n",
      "\n",
      "\n",
      "Thor Möger Pedersen\n",
      "First day 2011-10-12 00:00:00\n",
      "Last day 2012-10-10 00:00:00\n",
      "\n",
      "\n",
      "Lars Aagaard\n",
      "First day 2022-12-20 00:00:00\n",
      "Last day 2023-05-23 00:00:00\n",
      "\n",
      "\n",
      "Jørn Neergaard Larsen\n",
      "First day 2015-07-03 00:00:00\n",
      "Last day 2016-11-23 00:00:00\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "periods_start = []\n",
    "periods_end = []\n",
    "persons_missing_in_parMem = missing_party[missing_party['speaker_name'].apply(lambda x: x not in parMem['speaker_name'].tolist())]['speaker_name'].unique().tolist()\n",
    "for person in persons_missing_in_parMem:\n",
    "    print(person)\n",
    "    print(f\"First day {missing_party[missing_party['speaker_name'] == person]['date'].min()}\")\n",
    "    print(f\"Last day {missing_party[missing_party['speaker_name'] == person]['date'].max()}\")\n",
    "    periods_start.append(str(missing_party[missing_party['speaker_name'] == person]['date'].min())[0:10])\n",
    "    periods_end.append(str(missing_party[missing_party['speaker_name'] == person]['date'].max())[0:10])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these five persons, we find their political party on wikipedia and add them to the parliament members dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_missing_in_parMem_wiki = [e.replace(\" \", \"_\") for e in persons_missing_in_parMem]\n",
    "persons_missing_in_parMem_wiki = ['https://da.wikipedia.org/wiki/' + name for name in persons_missing_in_parMem]\n",
    "persons_missing_in_parMem_wiki\n",
    "\n",
    "speaker_partys = []\n",
    "for url in persons_missing_in_parMem_wiki:\n",
    "    page = requests.get(url)\n",
    "    page = BeautifulSoup(page.text, \"html.parser\")\n",
    "    table = page.find('table')\n",
    "    try:\n",
    "        party_label = table.find('th', {'scope': 'row', 'style': 'text-align:left'}, string=lambda s: 'Politisk' in str(s))\n",
    "        speaker_party = party_label.find_next('a').get_text(strip=True)\n",
    "    except AttributeError: #fails for Lars Aagaard, manually enter party\n",
    "        speaker_party = 'Moderaterne'\n",
    "    speaker_partys.append(speaker_party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_missing_in_parMem_df = pd.DataFrame({'speaker_name': persons_missing_in_parMem,\n",
    "                                             'speaker_party': speaker_partys,\n",
    "                                             'period_start': periods_start,\n",
    "                                             'period_end': periods_end})\n",
    "parMem = pd.concat([parMem, persons_missing_in_parMem_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if we have all the information in parliament members dataset (First merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge the dataset of speakers with missing party and parliament members dataset on two conditions:\n",
    "1. speaker_name has to match\n",
    "2. The date from the dataset of speakers with missing party has to be between the period_start and period_end\n",
    "\n",
    "Then we merge this merged dataset back onto the dataset of speakers with missing party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_party['date'] = pd.to_datetime(missing_party['date'])\n",
    "parMem['period_start'] = pd.to_datetime(parMem['period_start'])\n",
    "parMem['period_end'] = pd.to_datetime(parMem['period_end'])\n",
    "merged_df = pd.merge(missing_party, parMem, on='speaker_name', how='left')\n",
    "merged_df = merged_df[(merged_df['date'] >= merged_df['period_start']) & (merged_df['date'] <= merged_df['period_end'])]\n",
    "merged_df = merged_df.drop_duplicates()\n",
    "\n",
    "missing_party = pd.merge(missing_party, merged_df[['speaker_name', 'date', 'speaker_party']], on=['speaker_name', 'date'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a basic check to see if the dates worked well. We see that Lars Løkke Rasmussen has speech items both for Venstre and Moderaterne which is good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Venstre        2547\n",
       "Moderaterne     114\n",
       "Name: speaker_party, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_party[missing_party['speaker_name'] == 'Lars Løkke Rasmussen']['speaker_party'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We loop over the rows in the full speech dataset and insert the value from missing_party dataset if speaker_party is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_party_dict = {(row['speaker_name'], row['date']): row['speaker_party'] for _, row in missing_party.iterrows()}\n",
    "dspeech_copy = dspeech.copy()\n",
    "for index, row in dspeech_copy.iterrows():\n",
    "    speaker_name = row['speaker_name']\n",
    "    date = row['date']\n",
    "    if pd.isna(row['speaker_party']) and (speaker_name, date) in speaker_party_dict:\n",
    "        dspeech_copy.at[index, 'speaker_party'] = speaker_party_dict[(speaker_name, date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there are still missing values in speaker_party! Apparently there were 18 persons in the full speech dataset, who were speaking in the parliament as ministers at dates where the wikipedia pages did not inform that they were ministers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benedikte Kiær\n",
      "Lykke Friis\n",
      "Simon Emil Ammitzbøll-Bille\n",
      "Kaare Dybvad Bek\n",
      "Søren Pape Poulsen\n",
      "Thyra Frank\n",
      "Lars Christian Lilleholt\n",
      "Peter Hummelgaard\n",
      "Jeppe Kofod\n",
      "Tommy Ahlers\n",
      "Ulla Tørnæs\n",
      "Martin Lidegaard\n",
      "Christina Egelund\n",
      "Jeppe Bruus\n",
      "Dan Jørgensen\n",
      "Simon Emil Ammitzbøll\n",
      "Peter Christensen\n",
      "Karen Jespersen\n"
     ]
    }
   ],
   "source": [
    "periods_start = []\n",
    "periods_end = []\n",
    "persons_still_missing = dspeech_copy[dspeech_copy['speaker_party'].isnull()]['speaker_name'].unique().tolist()\n",
    "for person in persons_still_missing:\n",
    "    print(person)\n",
    "    periods_start.append(missing_party[missing_party['speaker_name'] == person]['date'].min())\n",
    "    periods_end.append(missing_party[missing_party['speaker_name'] == person]['date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed they were all ministers when speaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minister               6290\n",
       "fungerende minister       3\n",
       "Name: speaker_role, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dspeech_copy[dspeech_copy['speaker_party'].isnull()]['speaker_role'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these 18 persons, we find their political party on wikipedia and add them to the parliament members dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call here. Maybe you meant '==' instead of '='? (348842453.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[22], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    persons_still_missing_wiki.index('https://da.wikipedia.org/wiki/Peter_Christensen') = persons_still_missing_wiki.index('https://da.wikipedia.org/wiki/Peter_Christensen') + '_(politiker)'\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to function call here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "persons_still_missing_wiki = [e.replace(\" \", \"_\") for e in persons_still_missing]\n",
    "persons_still_missing_wiki = ['https://da.wikipedia.org/wiki/' + name for name in persons_still_missing_wiki]\n",
    "idx_peter_christensen = persons_still_missing_wiki.index('https://da.wikipedia.org/wiki/Peter_Christensen')\n",
    "persons_still_missing_wiki[idx_peter_christensen] = persons_still_missing_wiki[idx_peter_christensen] + '_(politiker)'\n",
    "\n",
    "speaker_partys = []\n",
    "for url in persons_still_missing_wiki:\n",
    "    page = requests.get(url)\n",
    "    page = BeautifulSoup(page.text, \"html.parser\")\n",
    "    table = page.find('table')\n",
    "    try:\n",
    "        party_label = table.find('th', {'scope': 'row', 'style': 'text-align:left'}, string=lambda s: 'Politisk' in str(s))\n",
    "        speaker_party = party_label.find_next('a').get_text(strip=True)\n",
    "        if speaker_party == '':\n",
    "            speaker_party = party_label.find_next('a')\n",
    "            speaker_party = speaker_party.find_next('a').get_text(strip=True)   \n",
    "    except AttributeError:\n",
    "        party_label = table.find('th', {'scope': 'row', 'style': 'text-align:left;vertical-align:top;'}, string=lambda s: 'Politisk' in str(s))\n",
    "        speaker_party = party_label.find_next('a').get_text(strip=True)\n",
    "    speaker_partys.append(speaker_party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://da.wikipedia.org/wiki/Benedikte_Kiær',\n",
       " 'https://da.wikipedia.org/wiki/Lykke_Friis',\n",
       " 'https://da.wikipedia.org/wiki/Simon_Emil_Ammitzbøll-Bille',\n",
       " 'https://da.wikipedia.org/wiki/Kaare_Dybvad_Bek',\n",
       " 'https://da.wikipedia.org/wiki/Søren_Pape_Poulsen',\n",
       " 'https://da.wikipedia.org/wiki/Thyra_Frank',\n",
       " 'https://da.wikipedia.org/wiki/Lars_Christian_Lilleholt',\n",
       " 'https://da.wikipedia.org/wiki/Peter_Hummelgaard',\n",
       " 'https://da.wikipedia.org/wiki/Jeppe_Kofod',\n",
       " 'https://da.wikipedia.org/wiki/Tommy_Ahlers',\n",
       " 'https://da.wikipedia.org/wiki/Ulla_Tørnæs',\n",
       " 'https://da.wikipedia.org/wiki/Martin_Lidegaard',\n",
       " 'https://da.wikipedia.org/wiki/Christina_Egelund',\n",
       " 'https://da.wikipedia.org/wiki/Jeppe_Bruus',\n",
       " 'https://da.wikipedia.org/wiki/Dan_Jørgensen',\n",
       " 'https://da.wikipedia.org/wiki/Simon_Emil_Ammitzbøll',\n",
       " 'https://da.wikipedia.org/wiki/Peter_Christensen',\n",
       " 'https://da.wikipedia.org/wiki/Karen_Jespersen']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persons_still_missing_wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_missing_in_parMem_df = pd.DataFrame({'speaker_name': persons_still_missing,\n",
    "                                             'speaker_party': speaker_partys,\n",
    "                                             'period_start': periods_start,\n",
    "                                             'period_end': periods_end})\n",
    "parMem = pd.concat([parMem, persons_missing_in_parMem_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then map party names to their short name, e.g. Venstre to V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Socialdemokratiet': 'S',\n",
       " 'Det Radikale Venstre': 'RV',\n",
       " 'Venstre': 'V',\n",
       " 'Enhedslisten': 'EL',\n",
       " 'Socialistisk Folkeparti': 'SF',\n",
       " 'Det Konservative Folkeparti': 'KF',\n",
       " 'Dansk Folkeparti': 'DF',\n",
       " 'Tjóðveldi': 'T',\n",
       " 'Siumut': 'SIU',\n",
       " 'Fólkaflokkurin': 'A',\n",
       " 'Inuit Ataqatigiit': 'IA',\n",
       " 'Sambandsflokkurin': 'SP',\n",
       " 'Ny Alliance': 'Y',\n",
       " 'Liberal Alliance': 'LA',\n",
       " 'Radikale Venstre': 'RV',\n",
       " 'Javnaðarflokkurin': 'JF',\n",
       " 'Alternativet': 'ALT',\n",
       " 'Nye Borgerlige': 'NB',\n",
       " 'Moderaterne': 'M',\n",
       " 'Danmarksdemokraterne': 'DD',\n",
       " 'Socialdemokraterne': 'S'}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "party_letters = ['S',\n",
    "               'RV',\n",
    "               'V',\n",
    "               'EL',\n",
    "               'SF', \n",
    "               'KF', \n",
    "               'DF', \n",
    "               'T',\n",
    "               'SIU',\n",
    "               'A',\n",
    "               'IA',\n",
    "               'SP',\n",
    "               'Y',\n",
    "               'LA',\n",
    "               'RV',\n",
    "               'JF',\n",
    "               'ALT',\n",
    "               'NB',\n",
    "               'M',\n",
    "               'DD',\n",
    "               'S'\n",
    "               ]\n",
    "party_letters_dict = dict(zip(parMem['speaker_party'].unique().tolist(), party_letters))\n",
    "party_letters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "parMem['speaker_party'] = parMem['speaker_party'].replace(party_letters_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same as earlier: merge the dataset of speakers with missing party and parliament members dataset on two conditions:\n",
    "1. speaker_name has to match\n",
    "2. The date from the dataset of speakers with missing party has to be between the period_start and period_end\n",
    "\n",
    "Then we merge this merged dataset back onto the dataset of speakers with missing party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_party['date'] = pd.to_datetime(missing_party['date'])\n",
    "missing_party = missing_party.drop(columns=['speaker_party'])\n",
    "parMem['period_start'] = pd.to_datetime(parMem['period_start'])\n",
    "parMem['period_end'] = pd.to_datetime(parMem['period_end'])\n",
    "merged_df = pd.merge(missing_party, parMem, on='speaker_name', how='left')\n",
    "merged_df = merged_df[(merged_df['date'] >= merged_df['period_start']) & (merged_df['date'] <= merged_df['period_end'])]\n",
    "merged_df = merged_df.drop_duplicates()\n",
    "\n",
    "missing_party = pd.merge(missing_party, merged_df[['speaker_name', 'date', 'speaker_party']], on=['speaker_name', 'date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['V', 'S', 'RV', 'M', 'KF', 'SF', 'LA'], dtype=object)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_party['speaker_party'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We loop over the rows in the full speech dataset and insert the value from missing_party dataset if speaker_party is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_party_dict = {(row['speaker_name'], row['date']): row['speaker_party'] for _, row in missing_party.iterrows()}\n",
    "for index, row in dspeech.iterrows():\n",
    "    speaker_name = row['speaker_name']\n",
    "    date = row['date']\n",
    "    if pd.isna(row['speaker_party']) and (speaker_name, date) in speaker_party_dict:\n",
    "        dspeech.at[index, 'speaker_party'] = speaker_party_dict[(speaker_name, date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 0 missing values in speaker_party!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dspeech['speaker_party'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspeech.drop(columns=[\"date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split intwo two datasets and save\n",
    "dspeech_1 = pa.Table.from_pandas(dspeech.iloc[: (len(dspeech) // 2)])\n",
    "dspeech_2 = pa.Table.from_pandas(dspeech.iloc[(len(dspeech) // 2) :])\n",
    "pq.write_table(dspeech_1, \"./data/data_speech1.parquet\")\n",
    "pq.write_table(dspeech_2, \"./data/data_speech2.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
