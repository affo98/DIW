{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_speech1 = pd.read_parquet('./data/data_speech1.parquet')\n",
    "data_speech2 = pd.read_parquet('./data/data_speech2.parquet')\n",
    "dspeech = pd.concat([data_speech1, data_speech2], axis=0)\n",
    "dmeeting = pd.read_parquet('./data/data_meeting.parquet')\n",
    "parMem = pd.read_parquet('./data/parliament_members.parquet')\n",
    "dspeech = pd.merge(dspeech, dmeeting[['meeting_id', 'date']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dataset with speakers that had missing party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_party = dspeech[dspeech['speaker_party'].isnull()] \n",
    "missing_party = pd.merge(missing_party, dmeeting[['meeting_id', 'date']])\n",
    "missing_party = missing_party[['speaker_name', 'date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add speakers that were not in parliament members dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some speakers with missing party were not in the parliament members dataset.\n",
    "We find these and scrape them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jørn Neergaard Larsen\n",
      "First day 2015-07-03 00:00:00\n",
      "Last day 2016-11-23 00:00:00\n",
      "\n",
      "\n",
      "Lars Aagaard\n",
      "First day 2022-12-20 00:00:00\n",
      "Last day 2023-05-23 00:00:00\n",
      "\n",
      "\n",
      "Joy Mogensen\n",
      "First day 2020-01-15 00:00:00\n",
      "Last day 2021-05-26 00:00:00\n",
      "\n",
      "\n",
      "Thor Möger Pedersen\n",
      "First day 2011-10-12 00:00:00\n",
      "Last day 2012-10-10 00:00:00\n",
      "\n",
      "\n",
      "Charlotte Sahl-Madsen\n",
      "First day 2010-02-25 00:00:00\n",
      "Last day 2011-05-26 00:00:00\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "periods_start = []\n",
    "periods_end = []\n",
    "persons_missing_in_parMem = missing_party[missing_party['speaker_name'].apply(lambda x: x not in parMem['speaker_name'].tolist())]['speaker_name'].unique().tolist()\n",
    "for person in persons_missing_in_parMem:\n",
    "    print(person)\n",
    "    print(f\"First day {missing_party[missing_party['speaker_name'] == person]['date'].min()}\")\n",
    "    print(f\"Last day {missing_party[missing_party['speaker_name'] == person]['date'].max()}\")\n",
    "    periods_start.append(str(missing_party[missing_party['speaker_name'] == person]['date'].min())[0:10])\n",
    "    periods_end.append(str(missing_party[missing_party['speaker_name'] == person]['date'].max())[0:10])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these five persons, we find their political party on wikipedia and add them to the parliament members dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_missing_in_parMem_wiki = [e.replace(\" \", \"_\") for e in persons_missing_in_parMem]\n",
    "persons_missing_in_parMem_wiki = ['https://da.wikipedia.org/wiki/' + name for name in persons_missing_in_parMem]\n",
    "persons_missing_in_parMem_wiki\n",
    "\n",
    "speaker_partys = []\n",
    "for url in persons_missing_in_parMem_wiki:\n",
    "    page = requests.get(url)\n",
    "    page = BeautifulSoup(page.text, \"html.parser\")\n",
    "    table = page.find('table')\n",
    "    try:\n",
    "        party_label = table.find('th', {'scope': 'row', 'style': 'text-align:left'}, string=lambda s: 'Politisk' in str(s))\n",
    "        speaker_party = party_label.find_next('a').get_text(strip=True)\n",
    "    except AttributeError: #fails for Lars Aagaard, manually enter party\n",
    "        speaker_party = 'Moderaterne'\n",
    "    speaker_partys.append(speaker_party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_missing_in_parMem_df = pd.DataFrame({'speaker_name': persons_missing_in_parMem,\n",
    "                                             'speaker_party': speaker_partys,\n",
    "                                             'period_start': periods_start,\n",
    "                                             'period_end': periods_end})\n",
    "parMem = pd.concat([parMem, persons_missing_in_parMem_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if we have all the information in parliament members dataset (First merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge the dataset of speakers with missing party and parliament members dataset on two conditions:\n",
    "1. speaker_name has to match\n",
    "2. The date from the dataset of speakers with missing party has to be between the period_start and period_end\n",
    "\n",
    "Then we merge this merged dataset back onto the dataset of speakers with missing party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_party['date'] = pd.to_datetime(missing_party['date'])\n",
    "parMem['period_start'] = pd.to_datetime(parMem['period_start'])\n",
    "parMem['period_end'] = pd.to_datetime(parMem['period_end'])\n",
    "merged_df = pd.merge(missing_party, parMem, on='speaker_name', how='left')\n",
    "merged_df = merged_df[(merged_df['date'] >= merged_df['period_start']) & (merged_df['date'] <= merged_df['period_end'])]\n",
    "merged_df = merged_df.drop_duplicates()\n",
    "\n",
    "missing_party = pd.merge(missing_party, merged_df[['speaker_name', 'date', 'speaker_party']], on=['speaker_name', 'date'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a basic check to see if the dates worked well. We see that Lars Løkke Rasmussen has speech items both for Venstre and Moderaterne which is good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Venstre        2547\n",
       "Moderaterne     114\n",
       "Name: speaker_party, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_party[missing_party['speaker_name'] == 'Lars Løkke Rasmussen']['speaker_party'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We loop over the rows in the full speech dataset and insert the value from missing_party dataset if speaker_party is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_party_dict = {(row['speaker_name'], row['date']): row['speaker_party'] for _, row in missing_party.iterrows()}\n",
    "for index, row in dspeech.iterrows():\n",
    "    speaker_name = row['speaker_name']\n",
    "    date = row['date']\n",
    "    if pd.isna(row['speaker_party']) and (speaker_name, date) in speaker_party_dict:\n",
    "        dspeech.at[index, 'speaker_party'] = speaker_party_dict[(speaker_name, date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there are still missing values in speaker_party! Apparently there were 18 persons in the full speech dataset, who were speaking in the parliament at dates where the wikipedia pages did not inform that they were ministers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persons that were not on wikipedia:\n",
      "Lars Christian Lilleholt\n",
      "Peter Christensen\n",
      "Martin Lidegaard\n",
      "Dan Jørgensen\n",
      "Ulla Tørnæs\n",
      "Jeppe Kofod\n",
      "Jeppe Bruus\n",
      "Kaare Dybvad Bek\n",
      "Peter Hummelgaard\n",
      "Christina Egelund\n",
      "Benedikte Kiær\n",
      "Lykke Friis\n",
      "Simon Emil Ammitzbøll\n",
      "Søren Pape Poulsen\n",
      "Thyra Frank\n",
      "Simon Emil Ammitzbøll-Bille\n",
      "Tommy Ahlers\n",
      "Karen Jespersen\n"
     ]
    }
   ],
   "source": [
    "print('Persons that were not on wikipedia:')\n",
    "periods_start = []\n",
    "periods_end = []\n",
    "persons_still_missing = dspeech[dspeech['speaker_party'].isnull()]['speaker_name'].unique().tolist()\n",
    "for person in persons_still_missing:\n",
    "    print(person)\n",
    "    periods_start.append(missing_party[missing_party['speaker_name'] == person]['date'].min())\n",
    "    periods_end.append(missing_party[missing_party['speaker_name'] == person]['date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed they were all ministers when speaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minister               6290\n",
       "fungerende minister       3\n",
       "Name: speaker_role, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dspeech[dspeech['speaker_party'].isnull()]['speaker_role'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these 18 persons, we find their political party on wikipedia and add them to the parliament members dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_still_missing_wiki = [e.replace(\" \", \"_\") for e in persons_still_missing]\n",
    "persons_still_missing_wiki = ['https://da.wikipedia.org/wiki/' + name for name in persons_still_missing_wiki]\n",
    "persons_still_missing_wiki[1] = persons_still_missing_wiki[1] + '_(politiker)'\n",
    "\n",
    "speaker_partys = []\n",
    "for url in persons_still_missing_wiki:\n",
    "    page = requests.get(url)\n",
    "    page = BeautifulSoup(page.text, \"html.parser\")\n",
    "    table = page.find('table')\n",
    "    try:\n",
    "        party_label = table.find('th', {'scope': 'row', 'style': 'text-align:left'}, string=lambda s: 'Politisk' in str(s))\n",
    "        speaker_party = party_label.find_next('a').get_text(strip=True)\n",
    "        if speaker_party == '':\n",
    "            speaker_party = party_label.find_next('a')\n",
    "            speaker_party = speaker_party.find_next('a').get_text(strip=True)   \n",
    "    except AttributeError:\n",
    "        party_label = table.find('th', {'scope': 'row', 'style': 'text-align:left;vertical-align:top;'}, string=lambda s: 'Politisk' in str(s))\n",
    "        speaker_party = party_label.find_next('a').get_text(strip=True)\n",
    "    speaker_partys.append(speaker_party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_missing_in_parMem_df = pd.DataFrame({'speaker_name': persons_still_missing,\n",
    "                                             'speaker_party': speaker_partys,\n",
    "                                             'period_start': periods_start,\n",
    "                                             'period_end': periods_end})\n",
    "parMem = pd.concat([parMem, persons_missing_in_parMem_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then map party names to their short name, e.g. Venstre to V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_letters = ['S',\n",
    "               'RV',\n",
    "               'V',\n",
    "               'EL',\n",
    "               'SF', \n",
    "               'KF', \n",
    "               'DF', \n",
    "               'T',\n",
    "               'SIU',\n",
    "               'A',\n",
    "               'IA',\n",
    "               'SP',\n",
    "               'Y',\n",
    "               'LA',\n",
    "               'RV',\n",
    "               'JF',\n",
    "               'ALT',\n",
    "               'NB',\n",
    "               'M',\n",
    "               'DD',\n",
    "               'S'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Socialdemokratiet': 'S',\n",
       " 'Det Radikale Venstre': 'RV',\n",
       " 'Venstre': 'V',\n",
       " 'Enhedslisten': 'EL',\n",
       " 'Socialistisk Folkeparti': 'SF',\n",
       " 'Det Konservative Folkeparti': 'KF',\n",
       " 'Dansk Folkeparti': 'DF',\n",
       " 'Tjóðveldi': 'T',\n",
       " 'Siumut': 'SIU',\n",
       " 'Fólkaflokkurin': 'A',\n",
       " 'Inuit Ataqatigiit': 'IA',\n",
       " 'Sambandsflokkurin': 'SP',\n",
       " 'Ny Alliance': 'Y',\n",
       " 'Liberal Alliance': 'LA',\n",
       " 'Radikale Venstre': 'RV',\n",
       " 'Javnaðarflokkurin': 'JF',\n",
       " 'Alternativet': 'ALT',\n",
       " 'Nye Borgerlige': 'NB',\n",
       " 'Moderaterne': 'M',\n",
       " 'Danmarksdemokraterne': 'DD',\n",
       " 'Socialdemokraterne': 'S'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict = dict(zip(parMem['speaker_party'].unique().tolist(), party_letters))\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same as earlier: merge the dataset of speakers with missing party and parliament members dataset on two conditions:\n",
    "1. speaker_name has to match\n",
    "2. The date from the dataset of speakers with missing party has to be between the period_start and period_end\n",
    "\n",
    "Then we merge this merged dataset back onto the dataset of speakers with missing party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_party['date'] = pd.to_datetime(missing_party['date'])\n",
    "missing_party = missing_party.drop(columns=['speaker_party'])\n",
    "parMem['period_start'] = pd.to_datetime(parMem['period_start'])\n",
    "parMem['period_end'] = pd.to_datetime(parMem['period_end'])\n",
    "merged_df = pd.merge(missing_party, parMem, on='speaker_name', how='left')\n",
    "merged_df = merged_df[(merged_df['date'] >= merged_df['period_start']) & (merged_df['date'] <= merged_df['period_end'])]\n",
    "merged_df = merged_df.drop_duplicates()\n",
    "\n",
    "missing_party = pd.merge(missing_party, merged_df[['speaker_name', 'date', 'speaker_party']], on=['speaker_name', 'date'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We loop over the rows in the full speech dataset and insert the value from missing_party dataset if speaker_party is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_party_dict = {(row['speaker_name'], row['date']): row['speaker_party'] for _, row in missing_party.iterrows()}\n",
    "for index, row in dspeech.iterrows():\n",
    "    speaker_name = row['speaker_name']\n",
    "    date = row['date']\n",
    "    if pd.isna(row['speaker_party']) and (speaker_name, date) in speaker_party_dict:\n",
    "        dspeech.at[index, 'speaker_party'] = speaker_party_dict[(speaker_name, date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 0 missing values in speaker_party!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dspeech['speaker_party'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspeech.drop(columns=[\"date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split intwo two datasets and save\n",
    "dspeech_1 = pa.Table.from_pandas(dspeech.iloc[: (len(dspeech) // 2)])\n",
    "dspeech_2 = pa.Table.from_pandas(dspeech.iloc[(len(dspeech) // 2) :])\n",
    "pq.write_table(dspeech_1, \"./data/data_speech1.parquet\")\n",
    "pq.write_table(dspeech_2, \"./data/data_speech2.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
