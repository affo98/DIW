{"cells":[{"cell_type":"code","execution_count":210,"metadata":{"executionInfo":{"elapsed":12214,"status":"ok","timestamp":1701591217670,"user":{"displayName":"e okuda","userId":"05819132607139876861"},"user_tz":-60},"id":"wC4kJKaLLOsy"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import spacy\n","from tqdm import tqdm\n","\n","from gensim.models import KeyedVectors\n","\n","import multiprocessing as mp\n","from spacy.tokens import Doc\n","from typing import List\n","from collections import Counter\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import lightgbm as lgb\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score, log_loss\n","import joblib\n","\n","import pyarrow as pa\n","import pyarrow.parquet as pq"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["%run helper_functions"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ZHr2x-PmaZ5o"},"outputs":[],"source":["data_path = \"./data/\"\n","annotation_data = pd.read_csv(data_path + 'annotation_data.csv')\n","df_tok1 = pd.read_parquet('./data/data_speech1_tok.parquet')\n","df_tok2 = pd.read_parquet('./data/data_speech2_tok.parquet')\n","df = pd.concat([df_tok1, df_tok2]).reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Load word lists and add features"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["word_list_C = pd.read_parquet('./data/word_lists/word_list_C.parquet')\n","word_list_C_augmented = pd.read_parquet('./data/word_lists/word_list_C_augmented.parquet')\n","word_list_C_complete = pd.concat([word_list_C, word_list_C_augmented])\n","\n","word_list_NC = pd.read_parquet('./data/word_lists/word_list_NC.parquet')\n","word_list_NC_augmented = pd.read_parquet('./data/word_lists/word_list_NC_augmented.parquet')\n","word_list_NC_complete = pd.concat([word_list_NC, word_list_NC_augmented])\n","\n","word_list_generic_augmented = pd.read_csv('./data/word_lists/word_list_generic_augmented.txt')\n","\n","\n","word_C_set = set(word_list_C_complete['word'])\n","word_NC_set = set(word_list_NC_complete['word'])\n","word_G_set = set(word_list_generic_augmented['word'])"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"z3SA2e7IW_DS"},"outputs":[],"source":["MODEL_FILE = '~/Desktop/dsl_skipgram_2020_m5_f500_epoch2_w5.model.w2v.bin'\n","word_vec_model = KeyedVectors.load_word2vec_format(MODEL_FILE, binary=True)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# add features\n","df = add_features(df, word_C_set,word_NC_set, word_G_set, word_vec_model)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["res_df = df[~df[[\"meeting_id\", \"agenda_item_id\"]].apply(tuple, axis=1).isin(annotation_data[[\"meeting_id\",\"agenda_item_id\"]].apply(tuple,axis=1))]\n","res_df['count_ratio'] = res_df['C_counts'] / res_df['NC_counts']"]},{"cell_type":"markdown","metadata":{"id":"QI4Q26Go_A8c"},"source":["### Create two trainings sets"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"sYtAFONUvMrL"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ratio: 9.91866055147262\n"]}],"source":["df_C = res_df.loc[(res_df.C_counts>2) |\n","                  (res_df.C_percent>5) & \n","                  (res_df.count_ratio>0.5), [\"average_vec\", \"meeting_id\", \"agenda_item_id\", \"speech_item_id\"]]\n","df_C[\"label\"] = \"C\"\n","\n","df_NC = res_df.loc[(res_df.NC_counts>0) & \n","                  (res_df.count_ratio<=0.5), [\"average_vec\", \"meeting_id\", \"agenda_item_id\", \"speech_item_id\"]]\n","df_NC[\"label\"] = \"NC\"\n","\n","print(\"Ratio:\" ,len(df_NC)/len(df_C))\n","df_train1 = pd.concat([df_C, df_NC])\n","\n","\n","df_train1_vec = df_train1['average_vec'].apply(lambda x: pd.Series(x))\n","df_train1 = pd.concat([df_train1_vec, df_train1[[\"label\",\"meeting_id\", \"agenda_item_id\", \"speech_item_id\"]]], axis=1).reset_index(drop=True)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Ratio: 9.920373542576117\n"]}],"source":["df_NC = res_df.loc[(res_df.C_counts<=1) |\n","                   (res_df.C_percent<10)\n","                   , [\"average_vec\", \"meeting_id\", \"agenda_item_id\", \"speech_item_id\"]]\n","df_NC = df_NC.sample(frac=0.55, random_state=42) # approximate the ratio from above\n","df_NC[\"label\"] = \"NC\"\n","\n","print(\"Ratio:\" ,len(df_NC)/len(df_C))\n","df_train2 = pd.concat([df_C, df_NC])\n","df_train2_vec = df_train2['average_vec'].apply(lambda x: pd.Series(x))\n","df_train2 = pd.concat([df_train2_vec, df_train2[[\"label\", 'meeting_id', 'agenda_item_id', 'speech_item_id']]], axis=1).reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"zR7USx2X_ZfS"},"source":["### Train a Classification Model"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":25902,"status":"ok","timestamp":1701517808748,"user":{"displayName":"e okuda","userId":"05819132607139876861"},"user_tz":-60},"id":"GzhQsVM_XOg5","outputId":"039dcbd6-e13b-4d77-8d69-f05230d5fe2f"},"outputs":[],"source":["def train_classifier(training_data:pd.DataFrame, type:str):\n","    # Assuming df is your DataFrame and it has a column named 'label'\n","    X = training_data.drop([\"label\", 'meeting_id', 'agenda_item_id', 'speech_item_id'], axis=1)  # replace 'features' with your actual feature columns\n","    y = training_data['label']\n","\n","    # Initialize StratifiedKFold\n","    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","    loss_values = []\n","    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n","        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","        # Initialize LGBMClassifier\n","        model = lgb.LGBMClassifier()\n","\n","        # Train the model\n","        model.fit(X_train, y_train)\n","\n","        # Make predictions\n","        y_pred = model.predict_proba(X_test)\n","\n","        # Calculate loss\n","        loss = log_loss(y_test, y_pred)\n","        loss_values.append(loss)\n","        print(f'Loss for fold {i+1}: {loss}')\n","\n","        # Save the model\n","        joblib.dump(model, './models/'+f'model_fold_{i+1}_{type}.joblib')\n","\n","    # Plot the loss values\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(range(1, len(loss_values) + 1), loss_values, marker='o')\n","    plt.title('Loss per fold')\n","    plt.xlabel('Fold number')\n","    plt.ylabel('Log Loss')\n","    plt.savefig(f'./figures/result_{type}.svg', format='svg')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_classifier(df_train1, '1')\n","train_classifier(df_train2, '2')"]},{"cell_type":"markdown","metadata":{},"source":["### Create test datasets"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[],"source":["test_annotation = df[df[[\"meeting_id\", \"agenda_item_id\"]].apply(tuple, axis=1).isin(annotation_data[[\"meeting_id\",\"agenda_item_id\"]].apply(tuple,axis=1))]\n","test_annotation = pd.merge(test_annotation, annotation_data[['meeting_id', \"agenda_item_id\",\"label\"]], on=['meeting_id', \"agenda_item_id\"])\n","test_res1 = res_df[~res_df[[\"meeting_id\", \"agenda_item_id\",\"speech_item_id\"]].apply(tuple, axis=1).isin(df_train1[[\"meeting_id\", \"agenda_item_id\",\"speech_item_id\"]].apply(tuple,axis=1))]\n","test_res2 = res_df[~res_df[[\"meeting_id\", \"agenda_item_id\",\"speech_item_id\"]].apply(tuple, axis=1).isin(df_train2[[\"meeting_id\", \"agenda_item_id\",\"speech_item_id\"]].apply(tuple,axis=1))]\n","test_res = test_res1[test_res1[[\"meeting_id\", \"agenda_item_id\",\"speech_item_id\"]].apply(tuple, axis=1).isin(test_res2[[\"meeting_id\", \"agenda_item_id\",\"speech_item_id\"]].apply(tuple,axis=1))]"]},{"cell_type":"markdown","metadata":{},"source":["### Predictions"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def make_predictions(test_data, type):\n","    test_data_vec = test_data['average_vec'].apply(lambda x: pd.Series(x))\n","    predictions = []\n","    for i in tqdm(range(5)):\n","        current_model = joblib.load(f'./models/model_fold_{i+1}_{type}.joblib')\n","        predictions.append(current_model.predict_proba(test_data_vec))\n","    test_data[[f'pred_C{type}', f'pred_NC{type}']] = np.mean(predictions, axis=0)\n","    return test_data"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>meeting_id</th>\n","      <th>agenda_item_id</th>\n","      <th>speech_item_id</th>\n","      <th>speech_item_tokenized</th>\n","      <th>C_counts</th>\n","      <th>NC_counts</th>\n","      <th>num_tokens</th>\n","      <th>C_percent</th>\n","      <th>NC_percent</th>\n","      <th>average_vec</th>\n","      <th>pred_C1</th>\n","      <th>pred_NC1</th>\n","      <th>pred_C2</th>\n","      <th>pred_NC2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>[tak, transportminister, optaget, fik, sikkerh...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>29</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>[-0.075431034, -0.0009323615, -0.0079427, -0.1...</td>\n","      <td>0.089070</td>\n","      <td>0.910930</td>\n","      <td>0.017997</td>\n","      <td>0.982003</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>[jamen, godt, spørgsmål, fyn, taler, penge, br...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>26</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>[-0.08959195, 0.03549706, 0.04963076, -0.16377...</td>\n","      <td>0.007105</td>\n","      <td>0.992895</td>\n","      <td>0.004486</td>\n","      <td>0.995514</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>[glad, høre, transportminister, mente, rent, f...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>48</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>[-0.035014614, -0.0067995302, 0.025162391, -0....</td>\n","      <td>0.020473</td>\n","      <td>0.979527</td>\n","      <td>0.007820</td>\n","      <td>0.992180</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>[jamen, spørgeren, siger, klart, forhandlinger...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>[-0.021872846, -0.013669523, -0.03367722, -0.2...</td>\n","      <td>0.009969</td>\n","      <td>0.990031</td>\n","      <td>0.002219</td>\n","      <td>0.997781</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>[rent, spark, sparker, åben, dør, siger, tak, ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>[-0.042932723, 0.02096915, 0.20651622, 0.03735...</td>\n","      <td>0.014420</td>\n","      <td>0.985580</td>\n","      <td>0.004252</td>\n","      <td>0.995748</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>369757</th>\n","      <td>1787</td>\n","      <td>22</td>\n","      <td>14</td>\n","      <td>[læst, artikel, børsen, gerne, kigge, leif, la...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>[-0.22993319, 0.035468224, 0.11045233, -0.1032...</td>\n","      <td>0.083551</td>\n","      <td>0.916449</td>\n","      <td>0.014567</td>\n","      <td>0.985433</td>\n","    </tr>\n","    <tr>\n","      <th>369758</th>\n","      <td>1787</td>\n","      <td>22</td>\n","      <td>16</td>\n","      <td>[set, svar, ministeren, ministeren, kunnet, ge...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>32</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>[-0.0990529, 0.05769629, 0.03520579, -0.187023...</td>\n","      <td>0.014823</td>\n","      <td>0.985177</td>\n","      <td>0.009774</td>\n","      <td>0.990226</td>\n","    </tr>\n","    <tr>\n","      <th>369759</th>\n","      <td>1787</td>\n","      <td>22</td>\n","      <td>18</td>\n","      <td>[kulturinstitutionerne, helhed, mærket, forrin...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>44</td>\n","      <td>0.0</td>\n","      <td>2.272727</td>\n","      <td>[-0.036421344, 0.078531206, 0.08241428, -0.119...</td>\n","      <td>0.010487</td>\n","      <td>0.989513</td>\n","      <td>0.022436</td>\n","      <td>0.977564</td>\n","    </tr>\n","    <tr>\n","      <th>369760</th>\n","      <td>1787</td>\n","      <td>22</td>\n","      <td>20</td>\n","      <td>[altså, ministerens, regnestykke, holder, sige...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>47</td>\n","      <td>0.0</td>\n","      <td>2.127660</td>\n","      <td>[-0.041592173, 0.006792875, 0.06115774, -0.154...</td>\n","      <td>0.037481</td>\n","      <td>0.962519</td>\n","      <td>0.038983</td>\n","      <td>0.961017</td>\n","    </tr>\n","    <tr>\n","      <th>369761</th>\n","      <td>1787</td>\n","      <td>22</td>\n","      <td>22</td>\n","      <td>[hvert, fald, generelle, niveau, stabilt, rigt...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>54</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>[-0.061307333, 0.045196056, 0.072656736, -0.05...</td>\n","      <td>0.017255</td>\n","      <td>0.982745</td>\n","      <td>0.015538</td>\n","      <td>0.984462</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>369762 rows × 14 columns</p>\n","</div>"],"text/plain":["        meeting_id  agenda_item_id  speech_item_id  \\\n","0                1               1               1   \n","1                1               1               3   \n","2                1               1               5   \n","3                1               1               7   \n","4                1               1               9   \n","...            ...             ...             ...   \n","369757        1787              22              14   \n","369758        1787              22              16   \n","369759        1787              22              18   \n","369760        1787              22              20   \n","369761        1787              22              22   \n","\n","                                    speech_item_tokenized  C_counts  \\\n","0       [tak, transportminister, optaget, fik, sikkerh...         0   \n","1       [jamen, godt, spørgsmål, fyn, taler, penge, br...         0   \n","2       [glad, høre, transportminister, mente, rent, f...         0   \n","3       [jamen, spørgeren, siger, klart, forhandlinger...         0   \n","4       [rent, spark, sparker, åben, dør, siger, tak, ...         0   \n","...                                                   ...       ...   \n","369757  [læst, artikel, børsen, gerne, kigge, leif, la...         0   \n","369758  [set, svar, ministeren, ministeren, kunnet, ge...         0   \n","369759  [kulturinstitutionerne, helhed, mærket, forrin...         0   \n","369760  [altså, ministerens, regnestykke, holder, sige...         0   \n","369761  [hvert, fald, generelle, niveau, stabilt, rigt...         0   \n","\n","        NC_counts  num_tokens  C_percent  NC_percent  \\\n","0               0          29        0.0    0.000000   \n","1               0          26        0.0    0.000000   \n","2               0          48        0.0    0.000000   \n","3               0          11        0.0    0.000000   \n","4               0           5        0.0    0.000000   \n","...           ...         ...        ...         ...   \n","369757          0           9        0.0    0.000000   \n","369758          0          32        0.0    0.000000   \n","369759          1          44        0.0    2.272727   \n","369760          1          47        0.0    2.127660   \n","369761          0          54        0.0    0.000000   \n","\n","                                              average_vec   pred_C1  pred_NC1  \\\n","0       [-0.075431034, -0.0009323615, -0.0079427, -0.1...  0.089070  0.910930   \n","1       [-0.08959195, 0.03549706, 0.04963076, -0.16377...  0.007105  0.992895   \n","2       [-0.035014614, -0.0067995302, 0.025162391, -0....  0.020473  0.979527   \n","3       [-0.021872846, -0.013669523, -0.03367722, -0.2...  0.009969  0.990031   \n","4       [-0.042932723, 0.02096915, 0.20651622, 0.03735...  0.014420  0.985580   \n","...                                                   ...       ...       ...   \n","369757  [-0.22993319, 0.035468224, 0.11045233, -0.1032...  0.083551  0.916449   \n","369758  [-0.0990529, 0.05769629, 0.03520579, -0.187023...  0.014823  0.985177   \n","369759  [-0.036421344, 0.078531206, 0.08241428, -0.119...  0.010487  0.989513   \n","369760  [-0.041592173, 0.006792875, 0.06115774, -0.154...  0.037481  0.962519   \n","369761  [-0.061307333, 0.045196056, 0.072656736, -0.05...  0.017255  0.982745   \n","\n","         pred_C2  pred_NC2  \n","0       0.017997  0.982003  \n","1       0.004486  0.995514  \n","2       0.007820  0.992180  \n","3       0.002219  0.997781  \n","4       0.004252  0.995748  \n","...          ...       ...  \n","369757  0.014567  0.985433  \n","369758  0.009774  0.990226  \n","369759  0.022436  0.977564  \n","369760  0.038983  0.961017  \n","369761  0.015538  0.984462  \n","\n","[369762 rows x 14 columns]"]},"execution_count":107,"metadata":{},"output_type":"execute_result"}],"source":["test_df_full_preds"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[],"source":["test_df_preds = make_predictions(test_res,'1')\n","test_df_preds = make_predictions(test_df_preds,'2')\n","\n","test_df_preds_anno = make_predictions(test_annotation,'1')\n","test_df_preds_anno = make_predictions(test_df_preds_anno,'2')\n","\n","test_df_full_preds = make_predictions(df, '1')\n","test_df_full_preds = make_predictions(test_df_full_preds, '2')"]},{"cell_type":"markdown","metadata":{},"source":["## Model evaluation"]},{"cell_type":"markdown","metadata":{},"source":["### Diagnostics\n","\n","1. Overall C/NC ratio.\n","2. Compare agenda annotation labels to model predictions (50/50)\n","3. Checking overlap between predictions from model 1 and 2\n","4. Reading speech items that model 1 predicted C and model 2 predicted NC\n"]},{"cell_type":"markdown","metadata":{},"source":["1. Overall C/NC ratio"]},{"cell_type":"code","execution_count":109,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.07530790075778473\n","0.037813512475592406\n"]}],"source":["print(test_df_full_preds[test_df_full_preds[\"pred_C1\"]>0.5].shape[0] / test_df_full_preds.shape[0])\n","print(test_df_full_preds[test_df_full_preds[\"pred_C2\"]>0.5].shape[0] / test_df_full_preds.shape[0])"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.06576071774816372\n","0.01123946300343428\n"]}],"source":["print(test_df_preds[test_df_preds[\"pred_C1\"]>0.5].shape[0] / test_df_preds.shape[0])\n","print(test_df_preds[test_df_preds[\"pred_C2\"]>0.5].shape[0] / test_df_preds.shape[0])"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.07258449620629277\n","0.033453600042447074\n"]}],"source":["print(test_df_preds_anno[test_df_preds_anno[\"pred_C1\"]>0.5].shape[0] / test_df_preds_anno.shape[0])\n","print(test_df_preds_anno[test_df_preds_anno[\"pred_C2\"]>0.5].shape[0] / test_df_preds_anno.shape[0])"]},{"cell_type":"markdown","metadata":{},"source":["2. Compare agenda annotation labels with majority voting"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[],"source":["test_annotation['pred_C2_binary'] = (test_annotation['pred_C2'] > 0.5).astype(int)\n","\n","# Calculate the percentage of 'C' predictions for each 'agenda_item_id'\n","voting_result = test_annotation.groupby(['meeting_id','agenda_item_id'])['pred_C2_binary'].mean()\n","\n","test_annotation['majority_vote_C2'] = test_annotation.set_index(['meeting_id', 'agenda_item_id']).index.map(lambda x: 'C' if voting_result.loc[x] > 0.5 else 'NC').values\n","\n","test_annotation['pred_C1_binary'] = (test_annotation['pred_C1'] > 0.5).astype(int)\n","\n","# Calculate the percentage of 'C' predictions for each 'agenda_item_id'\n","voting_result = test_annotation.groupby(['meeting_id','agenda_item_id'])['pred_C1_binary'].mean()\n","\n","test_annotation['majority_vote_C1'] = test_annotation.set_index(['meeting_id', 'agenda_item_id']).index.map(lambda x: 'C' if voting_result.loc[x] > 0.5 else 'NC').values\n","\n","class_mapping = {'NC':0, 'C':1}\n","test_annotation['label'] = test_annotation['label'].apply(lambda x: class_mapping[x])\n","test_annotation['majority_vote_C1'] = test_annotation['majority_vote_C1'].apply(lambda x: class_mapping[x])\n","test_annotation['majority_vote_C2'] = test_annotation['majority_vote_C2'].apply(lambda x: class_mapping[x])\n","\n","preds_comparison_C1 = test_annotation['label'].to_numpy() - test_annotation['majority_vote_C1'].to_numpy()\n","preds_comparison_C2 = test_annotation['label'].to_numpy() - test_annotation['majority_vote_C2'].to_numpy()\n","print('C1',(test_annotation.shape[0]-np.count_nonzero(preds_comparison_C1))/test_annotation.shape[0])\n","print('C2',(test_annotation.shape[0]-np.count_nonzero(preds_comparison_C2))/test_annotation.shape[0])\n","\n","print('TP C2',test_annotation[(test_annotation['majority_vote_C2'] == 1) & (test_annotation['label'] == 1)].groupby(['meeting_id','agenda_item_id']).first().shape[0])\n","print('FP C2',test_annotation[(test_annotation['majority_vote_C2'] == 1) & (test_annotation['label'] == 0)].groupby(['meeting_id','agenda_item_id']).first().shape[0])\n","print('FN C2',test_annotation[(test_annotation['majority_vote_C2'] == 0) & (test_annotation['label'] == 1)].groupby(['meeting_id','agenda_item_id']).first().shape[0])\n","print('TN C2',test_annotation[(test_annotation['majority_vote_C2'] == 0) & (test_annotation['label'] == 0)].groupby(['meeting_id','agenda_item_id']).first().shape[0])\n","print('\\n')\n","print('TP C1',test_annotation[(test_annotation['majority_vote_C1'] == 1) & (test_annotation['label'] == 1)].groupby(['meeting_id','agenda_item_id']).first().shape[0])\n","print('FP C1',test_annotation[(test_annotation['majority_vote_C1'] == 1) & (test_annotation['label'] == 0)].groupby(['meeting_id','agenda_item_id']).first().shape[0])\n","print('FN C1',test_annotation[(test_annotation['majority_vote_C1'] == 0) & (test_annotation['label'] == 1)].groupby(['meeting_id','agenda_item_id']).first().shape[0])\n","print('TN C1',test_annotation[(test_annotation['majority_vote_C1'] == 0) & (test_annotation['label'] == 0)].groupby(['meeting_id','agenda_item_id']).first().shape[0])"]},{"cell_type":"markdown","metadata":{},"source":["3. Checking overlap between predictions from model 1 and 2"]},{"cell_type":"code","execution_count":177,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model 2 predicts C where Model 1 predicts NC: 49\n","Model 1 predicts C where Model 2 predicts NC: 13913\n"]}],"source":["test_df_full_preds['label1'] = np.where(test_df_full_preds['pred_C1']>0.5, 'C', 'NC')\n","test_df_full_preds['label2'] = np.where(test_df_full_preds['pred_C2']>0.5, 'C', 'NC')\n","print('Model 2 predicts C where Model 1 predicts NC:' ,test_df_full_preds[ (test_df_full_preds['label2']=='C') & (test_df_full_preds['label1']=='NC')].shape[0])\n","print('Model 1 predicts C where Model 2 predicts NC:' ,test_df_full_preds[ (test_df_full_preds['label1']=='C') & (test_df_full_preds['label2']=='NC')].shape[0])"]},{"cell_type":"markdown","metadata":{},"source":["4. Reading speech items that model 1 predicted C and model 2 predicted NC"]},{"cell_type":"code","execution_count":207,"metadata":{},"outputs":[],"source":["pd.set_option('display.max_colwidth', 200)\n","test_df_full_preds[ (test_df_full_preds['label1']=='C') & (test_df_full_preds['label2']=='NC') & (test_df_full_preds['num_tokens'] < test_df_full_preds['num_tokens'].mean())]['speech_item_tokenized'][0:50]"]},{"cell_type":"code","execution_count":208,"metadata":{},"outputs":[],"source":["pd.set_option('display.max_colwidth', 50)"]},{"cell_type":"markdown","metadata":{},"source":["## Conclusion: We choose Model 1!"]},{"cell_type":"markdown","metadata":{},"source":["### Make predictions on entire dataset and save"]},{"cell_type":"code","execution_count":204,"metadata":{},"outputs":[],"source":["data_speech1 = pd.read_parquet('./data/data_speech1.parquet')\n","data_speech2 = pd.read_parquet('./data/data_speech2.parquet')\n","data_speech3 = pd.read_parquet('./data/data_speech3.parquet')\n","dspeech = pd.concat([data_speech1, data_speech2, data_speech3], axis=0)"]},{"cell_type":"code","execution_count":205,"metadata":{},"outputs":[],"source":["dspeech = pd.merge(dspeech, test_df_full_preds[['meeting_id', 'agenda_item_id', 'speech_item_id', 'pred_C1', 'pred_NC1']])\n","dspeech['label'] = np.where(dspeech['pred_C1']>0.5, 'C', 'NC')\n","del dspeech['pred_C1'], dspeech['pred_NC1']"]},{"cell_type":"code","execution_count":213,"metadata":{},"outputs":[],"source":["split_point_1 = len(dspeech) // 3\n","split_point_2 = 2 * (len(dspeech) // 3)\n","\n","dspeech_1 = pa.Table.from_pandas(dspeech.iloc[:split_point_1])\n","dspeech_2 = pa.Table.from_pandas(dspeech.iloc[split_point_1:split_point_2])\n","dspeech_3 = pa.Table.from_pandas(dspeech.iloc[split_point_2:])\n","\n","# pq.write_table(dspeech_1, \"./data/data_speech1.parquet\")\n","# pq.write_table(dspeech_1, \"./data/data_speech2.parquet\")\n","# pq.write_table(dspeech_1, \"./data/data_speech3.parquet\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO+/Tpw16yNK9tpyDgIuGu3","machine_shape":"hm","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
