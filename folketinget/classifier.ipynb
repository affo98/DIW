{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":12214,"status":"ok","timestamp":1701591217670,"user":{"displayName":"e okuda","userId":"05819132607139876861"},"user_tz":-60},"id":"wC4kJKaLLOsy"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import spacy\n","from tqdm import tqdm\n","\n","from gensim.models import KeyedVectors\n","\n","import multiprocessing as mp\n","from spacy.tokens import Doc\n","from typing import List\n","from collections import Counter\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import lightgbm as lgb\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score, log_loss\n","import joblib\n","\n","import pyarrow as pa\n","import pyarrow.parquet as pq"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["%run helper_functions"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ZHr2x-PmaZ5o"},"outputs":[],"source":["data_path = \"./data/\"\n","annotation_data = pd.read_parquet(data_path + 'data_annotation.parquet')\n","df_tok1 = pd.read_parquet('./data/data_speech1_tok.parquet')\n","df_tok2 = pd.read_parquet('./data/data_speech2_tok.parquet')\n","df = pd.concat([df_tok1, df_tok2]).reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Load word lists and add features"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["word_list_C = pd.read_parquet('./data/word_lists/word_list_C.parquet')\n","word_list_C_augmented = pd.read_parquet('./data/word_lists/word_list_C_augmented.parquet')\n","word_list_C_complete = pd.concat([word_list_C, word_list_C_augmented])\n","\n","word_list_NC = pd.read_parquet('./data/word_lists/word_list_NC.parquet')\n","word_list_NC_augmented = pd.read_parquet('./data/word_lists/word_list_NC_augmented.parquet')\n","word_list_NC_complete = pd.concat([word_list_NC, word_list_NC_augmented])\n","\n","word_list_generic_augmented = pd.read_csv('./data/word_lists/word_list_generic_augmented.txt')\n","\n","\n","word_C_set = set(word_list_C_complete['word'])\n","word_NC_set = set(word_list_NC_complete['word'])\n","word_G_set = set(word_list_generic_augmented['word'])"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"z3SA2e7IW_DS"},"outputs":[],"source":["MODEL_FILE = '~/Desktop/dsl_skipgram_2020_m5_f500_epoch2_w5.model.w2v.bin'\n","word_vec_model = KeyedVectors.load_word2vec_format(MODEL_FILE, binary=True)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# add features\n","df = add_features(df, word_C_set,word_NC_set, word_G_set, word_vec_model)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["res_df = df[~df[[\"meeting_id\", \"agenda_item_id\"]].apply(tuple, axis=1).isin(annotation_data[[\"meeting_id\",\"agenda_item_id\"]].apply(tuple,axis=1))]\n","res_df['count_ratio'] = res_df['C_counts'] / res_df['NC_counts']"]},{"cell_type":"markdown","metadata":{"id":"QI4Q26Go_A8c"},"source":["### Create two trainings sets"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"sYtAFONUvMrL"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ratio: 9.91866055147262\n"]}],"source":["df_C = res_df.loc[(res_df.C_counts>2) |\n","                  (res_df.C_percent>5) & \n","                  (res_df.count_ratio>0.5), [\"average_vec\", \"meeting_id\", \"agenda_item_id\", \"speech_item_id\"]]\n","df_C[\"label\"] = \"C\"\n","\n","df_NC = res_df.loc[(res_df.NC_counts>0) & \n","                  (res_df.count_ratio<=0.5), [\"average_vec\", \"meeting_id\", \"agenda_item_id\", \"speech_item_id\"]]\n","df_NC[\"label\"] = \"NC\"\n","\n","print(\"Ratio:\" ,len(df_NC)/len(df_C))\n","df_train1 = pd.concat([df_C, df_NC])\n","\n","\n","df_train1_vec = df_train1['average_vec'].apply(lambda x: pd.Series(x))\n","df_train1 = pd.concat([df_train1_vec, df_train1[[\"label\",\"meeting_id\", \"agenda_item_id\", \"speech_item_id\"]]], axis=1).reset_index(drop=True)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Ratio: 9.920373542576117\n"]}],"source":["df_NC = res_df.loc[(res_df.C_counts<=1) |\n","                   (res_df.C_percent<10)\n","                   , [\"average_vec\", \"meeting_id\", \"agenda_item_id\", \"speech_item_id\"]]\n","df_NC = df_NC.sample(frac=0.55, random_state=42) # approximate the ratio from above\n","df_NC[\"label\"] = \"NC\"\n","\n","print(\"Ratio:\" ,len(df_NC)/len(df_C))\n","df_train2 = pd.concat([df_C, df_NC])\n","df_train2_vec = df_train2['average_vec'].apply(lambda x: pd.Series(x))\n","df_train2 = pd.concat([df_train2_vec, df_train2[[\"label\", 'meeting_id', 'agenda_item_id', 'speech_item_id']]], axis=1).reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"zR7USx2X_ZfS"},"source":["### Train a Classification Model"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":25902,"status":"ok","timestamp":1701517808748,"user":{"displayName":"e okuda","userId":"05819132607139876861"},"user_tz":-60},"id":"GzhQsVM_XOg5","outputId":"039dcbd6-e13b-4d77-8d69-f05230d5fe2f"},"outputs":[],"source":["def train_classifier(training_data:pd.DataFrame, type:str):\n","    # Assuming df is your DataFrame and it has a column named 'label'\n","    X = training_data.drop([\"label\", 'meeting_id', 'agenda_item_id', 'speech_item_id'], axis=1)  # replace 'features' with your actual feature columns\n","    y = training_data['label']\n","\n","    # Initialize StratifiedKFold\n","    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","    loss_values = []\n","    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n","        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","        # Initialize LGBMClassifier\n","        model = lgb.LGBMClassifier()\n","\n","        # Train the model\n","        model.fit(X_train, y_train)\n","\n","        # Make predictions\n","        y_pred = model.predict_proba(X_test)\n","\n","        # Calculate loss\n","        loss = log_loss(y_test, y_pred)\n","        loss_values.append(loss)\n","        print(f'Loss for fold {i+1}: {loss}')\n","\n","        # Save the model\n","        joblib.dump(model, './models/'+f'model_fold_{i+1}_{type}.joblib')\n","\n","    # Plot the loss values\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(range(1, len(loss_values) + 1), loss_values, marker='o')\n","    plt.title('Loss per fold')\n","    plt.xlabel('Fold number')\n","    plt.ylabel('Log Loss')\n","    plt.savefig(f'./figures/result_{type}.svg', format='svg')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_classifier(df_train1, '1')\n","train_classifier(df_train2, '2')"]},{"cell_type":"markdown","metadata":{},"source":["### Create test datasets"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[],"source":["test_annotation = df[df[[\"meeting_id\", \"agenda_item_id\"]].apply(tuple, axis=1).isin(annotation_data[[\"meeting_id\",\"agenda_item_id\"]].apply(tuple,axis=1))]\n","test_annotation = pd.merge(test_annotation, annotation_data[['meeting_id', \"agenda_item_id\",\"label\"]], on=['meeting_id', \"agenda_item_id\"])\n","test_res1 = res_df[~res_df[[\"meeting_id\", \"agenda_item_id\",\"speech_item_id\"]].apply(tuple, axis=1).isin(df_train1[[\"meeting_id\", \"agenda_item_id\",\"speech_item_id\"]].apply(tuple,axis=1))]\n","test_res2 = res_df[~res_df[[\"meeting_id\", \"agenda_item_id\",\"speech_item_id\"]].apply(tuple, axis=1).isin(df_train2[[\"meeting_id\", \"agenda_item_id\",\"speech_item_id\"]].apply(tuple,axis=1))]\n","test_res = test_res1[test_res1[[\"meeting_id\", \"agenda_item_id\",\"speech_item_id\"]].apply(tuple, axis=1).isin(test_res2[[\"meeting_id\", \"agenda_item_id\",\"speech_item_id\"]].apply(tuple,axis=1))]"]},{"cell_type":"markdown","metadata":{},"source":["### Predictions"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def make_predictions(test_data, type):\n","    test_data_vec = test_data['average_vec'].apply(lambda x: pd.Series(x))\n","    predictions = []\n","    for i in tqdm(range(5)):\n","        current_model = joblib.load(f'./models/model_fold_{i+1}_{type}.joblib')\n","        predictions.append(current_model.predict_proba(test_data_vec))\n","    test_data[[f'pred_C{type}', f'pred_NC{type}']] = np.mean(predictions, axis=0)\n","    return test_data"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[],"source":["test_df_preds = make_predictions(test_res,'1')\n","test_df_preds = make_predictions(test_df_preds,'2')\n","\n","test_df_preds_anno = make_predictions(test_annotation,'1')\n","test_df_preds_anno = make_predictions(test_df_preds_anno,'2')\n","\n","test_df_full_preds = make_predictions(df, '1')\n","test_df_full_preds = make_predictions(test_df_full_preds, '2')"]},{"cell_type":"markdown","metadata":{},"source":["## Model evaluation"]},{"cell_type":"markdown","metadata":{},"source":["### Diagnostics\n","\n","1. Overall C/NC ratio.\n","2. Compare agenda annotation labels to model predictions (50/50)\n","3. Checking overlap between predictions from model 1 and 2\n","4. Reading speech items that model 1 predicted C and model 2 predicted NC\n"]},{"cell_type":"markdown","metadata":{},"source":["1. Overall C/NC ratio"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.07530790075778473\n","0.037813512475592406\n"]}],"source":["print(test_df_full_preds[test_df_full_preds[\"pred_C1\"]>0.5].shape[0] / test_df_full_preds.shape[0])\n","print(test_df_full_preds[test_df_full_preds[\"pred_C2\"]>0.5].shape[0] / test_df_full_preds.shape[0])"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.06576071774816372\n","0.01123946300343428\n"]}],"source":["print(test_df_preds[test_df_preds[\"pred_C1\"]>0.5].shape[0] / test_df_preds.shape[0])\n","print(test_df_preds[test_df_preds[\"pred_C2\"]>0.5].shape[0] / test_df_preds.shape[0])"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.07258449620629277\n","0.033453600042447074\n"]}],"source":["print(test_df_preds_anno[test_df_preds_anno[\"pred_C1\"]>0.5].shape[0] / test_df_preds_anno.shape[0])\n","print(test_df_preds_anno[test_df_preds_anno[\"pred_C2\"]>0.5].shape[0] / test_df_preds_anno.shape[0])"]},{"cell_type":"markdown","metadata":{},"source":["2. Compare agenda annotation labels with majority voting"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[],"source":["test_annotation['pred_C2_binary'] = (test_annotation['pred_C2'] > 0.5).astype(int)\n","\n","# Calculate the percentage of 'C' predictions for each 'agenda_item_id'\n","voting_result = test_annotation.groupby(['meeting_id','agenda_item_id'])['pred_C2_binary'].mean()\n","\n","test_annotation['majority_vote_C2'] = test_annotation.set_index(['meeting_id', 'agenda_item_id']).index.map(lambda x: 'C' if voting_result.loc[x] > 0.5 else 'NC').values\n","\n","test_annotation['pred_C1_binary'] = (test_annotation['pred_C1'] > 0.5).astype(int)\n","\n","# Calculate the percentage of 'C' predictions for each 'agenda_item_id'\n","voting_result = test_annotation.groupby(['meeting_id','agenda_item_id'])['pred_C1_binary'].mean()\n","\n","test_annotation['majority_vote_C1'] = test_annotation.set_index(['meeting_id', 'agenda_item_id']).index.map(lambda x: 'C' if voting_result.loc[x] > 0.5 else 'NC').values\n","\n","class_mapping = {'NC':0, 'C':1}\n","test_annotation['label'] = test_annotation['label'].apply(lambda x: class_mapping[x])\n","test_annotation['majority_vote_C1'] = test_annotation['majority_vote_C1'].apply(lambda x: class_mapping[x])\n","test_annotation['majority_vote_C2'] = test_annotation['majority_vote_C2'].apply(lambda x: class_mapping[x])\n","\n","preds_comparison_C1 = test_annotation['label'].to_numpy() - test_annotation['majority_vote_C1'].to_numpy()\n","preds_comparison_C2 = test_annotation['label'].to_numpy() - test_annotation['majority_vote_C2'].to_numpy()\n","print('C1',(test_annotation.shape[0]-np.count_nonzero(preds_comparison_C1))/test_annotation.shape[0])\n","print('C2',(test_annotation.shape[0]-np.count_nonzero(preds_comparison_C2))/test_annotation.shape[0])\n","\n","print('TP C2',test_annotation[(test_annotation['majority_vote_C2'] == 1) & (test_annotation['label'] == 1)].groupby(['meeting_id','agenda_item_id']).first().shape[0])\n","print('FP C2',test_annotation[(test_annotation['majority_vote_C2'] == 1) & (test_annotation['label'] == 0)].groupby(['meeting_id','agenda_item_id']).first().shape[0])\n","print('FN C2',test_annotation[(test_annotation['majority_vote_C2'] == 0) & (test_annotation['label'] == 1)].groupby(['meeting_id','agenda_item_id']).first().shape[0])\n","print('TN C2',test_annotation[(test_annotation['majority_vote_C2'] == 0) & (test_annotation['label'] == 0)].groupby(['meeting_id','agenda_item_id']).first().shape[0])\n","print('\\n')\n","print('TP C1',test_annotation[(test_annotation['majority_vote_C1'] == 1) & (test_annotation['label'] == 1)].groupby(['meeting_id','agenda_item_id']).first().shape[0])\n","print('FP C1',test_annotation[(test_annotation['majority_vote_C1'] == 1) & (test_annotation['label'] == 0)].groupby(['meeting_id','agenda_item_id']).first().shape[0])\n","print('FN C1',test_annotation[(test_annotation['majority_vote_C1'] == 0) & (test_annotation['label'] == 1)].groupby(['meeting_id','agenda_item_id']).first().shape[0])\n","print('TN C1',test_annotation[(test_annotation['majority_vote_C1'] == 0) & (test_annotation['label'] == 0)].groupby(['meeting_id','agenda_item_id']).first().shape[0])"]},{"cell_type":"markdown","metadata":{},"source":["3. Checking overlap between predictions from model 1 and 2"]},{"cell_type":"code","execution_count":177,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model 2 predicts C where Model 1 predicts NC: 49\n","Model 1 predicts C where Model 2 predicts NC: 13913\n"]}],"source":["test_df_full_preds['label1'] = np.where(test_df_full_preds['pred_C1']>0.5, 'C', 'NC')\n","test_df_full_preds['label2'] = np.where(test_df_full_preds['pred_C2']>0.5, 'C', 'NC')\n","print('Model 2 predicts C where Model 1 predicts NC:' ,test_df_full_preds[ (test_df_full_preds['label2']=='C') & (test_df_full_preds['label1']=='NC')].shape[0])\n","print('Model 1 predicts C where Model 2 predicts NC:' ,test_df_full_preds[ (test_df_full_preds['label1']=='C') & (test_df_full_preds['label2']=='NC')].shape[0])"]},{"cell_type":"markdown","metadata":{},"source":["4. Reading speech items that model 1 predicted C and model 2 predicted NC"]},{"cell_type":"code","execution_count":207,"metadata":{},"outputs":[],"source":["pd.set_option('display.max_colwidth', 200)\n","test_df_full_preds[ (test_df_full_preds['label1']=='C') & (test_df_full_preds['label2']=='NC') & (test_df_full_preds['num_tokens'] < test_df_full_preds['num_tokens'].mean())]['speech_item_tokenized'][0:50]"]},{"cell_type":"code","execution_count":208,"metadata":{},"outputs":[],"source":["pd.set_option('display.max_colwidth', 50)"]},{"cell_type":"markdown","metadata":{},"source":["## Conclusion: We choose Model 1!"]},{"cell_type":"markdown","metadata":{},"source":["### Make predictions on entire dataset and save"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 5/5 [00:11<00:00,  2.37s/it]\n","100%|██████████| 5/5 [00:11<00:00,  2.21s/it]\n"]}],"source":["test_df_full_preds = make_predictions(df, '1')\n","test_df_full_preds = make_predictions(test_df_full_preds, '2')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["data_speech1 = pd.read_parquet('./data/odata_speech1.parquet')\n","data_speech2 = pd.read_parquet('./data/odata_speech2.parquet')\n","data_speech3 = pd.read_parquet('./data/odata_speech3.parquet')\n","dspeech = pd.concat([data_speech1, data_speech2, data_speech3], axis=0)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["dspeech = pd.merge(dspeech, test_df_full_preds[['meeting_id', 'agenda_item_id', 'speech_item_id', 'pred_C1', 'pred_NC1']])\n","dspeech['label'] = np.where(dspeech['pred_C1']>0.5, 'C', 'NC')\n","del dspeech['pred_C1'], dspeech['pred_NC1']"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["split_point_1 = len(dspeech) // 3\n","split_point_2 = 2 * (len(dspeech) // 3)\n","\n","dspeech_1 = pa.Table.from_pandas(dspeech.iloc[:split_point_1])\n","dspeech_2 = pa.Table.from_pandas(dspeech.iloc[split_point_1:split_point_2])\n","dspeech_3 = pa.Table.from_pandas(dspeech.iloc[split_point_2:])\n","\n","# pq.write_table(dspeech_1, \"./data/data_speech1.parquet\")\n","# pq.write_table(dspeech_2, \"./data/data_speech2.parquet\")\n","# pq.write_table(dspeech_3, \"./data/data_speech3.parquet\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO+/Tpw16yNK9tpyDgIuGu3","machine_shape":"hm","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
